{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":13806,"status":"ok","timestamp":1729341587232,"user":{"displayName":"藤枝元輝","userId":"06257803041764381546"},"user_tz":-540},"id":"0zgdWEPKuVCQ"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.models as models\n","import cv2\n","from torchvision import transforms\n","from torch.utils.data import Dataset,DataLoader,random_split\n","from PIL import Image\n","import os\n","import time\n","import copy\n","import torch.nn.utils.rnn as rnn_utils\n","import numpy as np"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1729341587233,"user":{"displayName":"藤枝元輝","userId":"06257803041764381546"},"user_tz":-540},"id":"s7Wp9B8CMQR2"},"outputs":[],"source":["from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","class CNN_LSTM_Model(nn.Module):\n","  def __init__(self,num_classes,hidden_size,num_layers):\n","    super(CNN_LSTM_Model,self).__init__()\n","\n","    resnet = models.resnet18(pretrained=True)\n","    self.cnn = nn.Sequential(*list(resnet.children())[:-1])\n","\n","    self.lstm = nn.LSTM(input_size=resnet.fc.in_features,hidden_size=hidden_size,num_layers=num_layers,batch_first=True)\n","\n","    self.fc = nn.Linear(hidden_size,num_classes)\n","\n","  def forward(self,inputs,lengths):\n","    batch_size,timesteps,C,H,W = inputs.size()\n","    c_out = []\n","    for t in range(timesteps):\n","      cnn_out = self.cnn(inputs[:,t,:,:,:])\n","      cnn_out = cnn_out.view(batch_size,-1)\n","      c_out.append(cnn_out)\n","    c_out = torch.stack(c_out,dim=1)\n","    output,(hn,cn) = self.lstm(c_out)\n","    output = self.fc(output[:,-1,:])\n","\n","    return output,c_out"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1729341588939,"user":{"displayName":"藤枝元輝","userId":"06257803041764381546"},"user_tz":-540},"id":"FzvH-OhQC2IC"},"outputs":[],"source":["def movie2frame(video_path,max_frames,transform):\n","  cap = cv2.VideoCapture(video_path)\n","  frames = []\n","  mask = []\n","  while True:\n","    ret,frame = cap.read()\n","    if not ret:\n","      break\n","    frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n","    frame = transform(frame)\n","    mask.append(1)\n","    frames.append(frame)\n","\n","  while len(frames) < max_frames:\n","    frames.append(torch.zeros_like(frames[0]))\n","    mask.append(0)\n","  return torch.stack(frames),torch.tensor(mask)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def frame2torch(dir_path,transform): \n","    files = os.listdir(dir_path)\n","    files.sort()\n","    frames = []\n","    for file in files:\n","        image = np.array(Image.open(os.path.join(dir_path,file)))\n","        image = transform(image)\n","        frames.append(image)\n","    return torch.stack(frames)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1729341588939,"user":{"displayName":"藤枝元輝","userId":"06257803041764381546"},"user_tz":-540},"id":"7WNKk9Yn_vhu"},"outputs":[],"source":["# import re\n","# import pandas as pd\n","# class CustomImageDataset(Dataset):\n","#   def __init__(self,img_dir,transform):\n","#     self.img_dir = img_dir\n","#     self.transform = transform\n","#     self.img_labels = []\n","#     self.folder_name2label = {}\n","#     target = \"Train\" if re.search(\"Train\",img_dir) else \"Test\"\n","#     df = pd.read_csv(img_dir+\"_csv\"+\"/\"+target+\".csv\")\n","#     for index,row in df.iterrows():\n","#       self.folder_name2label[row[\"video_id\"]] = row[\"label_id\"]\n","#     for folder in os.listdir(img_dir):\n","#       if folder != \".DS_Store\":\n","#         self.img_labels.append((self.img_dir+\"/\"+folder,self.folder_name2label[int(folder)]))      \n","\n","#   def __len__(self):\n","#     return len(self.img_labels)\n","  \n","#   def __getitem__(self,idx):\n","#     img_path,label = self.img_labels[idx]\n","#     frames = frame2torch(img_path,self.transform)\n","#     return frames,label"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2324,"status":"ok","timestamp":1729341591258,"user":{"displayName":"藤枝元輝","userId":"06257803041764381546"},"user_tz":-540},"id":"Eek2Gq5Sj9cz","outputId":"076e840c-fd9b-4ea8-d820-b1f5910624af"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'Train': 13302, 'Test': 1936}\n"]}],"source":["from CustomDataset.Dataset import CustomImageDataset\n","data_transforms = {\n","    \"Train\":transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Resize((96,96)),\n","        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n","        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n","        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n","    ]),\n","    \"Test\":transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Resize((96,96)),\n","        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n","    ]),\n","}\n","\n","data_dir = \"./\"\n","image_datasets = {x:CustomImageDataset(os.path.join(data_dir,x),data_transforms[x]) for x in [\"Train\",\"Test\"]}\n","\n","img_dataloaders = {x:torch.utils.data.DataLoader(image_datasets[x],batch_size=2,shuffle=True,num_workers=1)\n","                for x in [\"Train\",\"Test\"]}\n","dataset_sizes = {x:len(image_datasets[x]) for x in [\"Train\",\"Test\"]}\n","\n","print(dataset_sizes)\n"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([2, 37, 3, 96, 96])\n","torch.Size([2])\n","torch.Size([2, 37, 3, 96, 96])\n","torch.Size([2])\n","torch.Size([2, 37, 3, 96, 96])\n","torch.Size([2])\n","torch.Size([2, 37, 3, 96, 96])\n","torch.Size([2])\n"]}],"source":["dataloader = img_dataloaders[\"Train\"]\n","for i ,data in enumerate(dataloader):\n","    print(data[0].shape)\n","    print(data[1].shape)\n","    if i == 3:\n","        break\n","    i += 1\n"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":280,"status":"ok","timestamp":1729341591534,"user":{"displayName":"藤枝元輝","userId":"06257803041764381546"},"user_tz":-540},"id":"KrjZFOtnfN6f"},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/genki/.local/share/virtualenvs/gesture_classifying-w3jCci-Q/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/Users/genki/.local/share/virtualenvs/gesture_classifying-w3jCci-Q/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]}],"source":["net = CNN_LSTM_Model(5,128,1)\n","\n","#OS正則化のパラメータ\n","regularization_param = 0.01\n","\n","loss_function = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(),lr=0.0001,momentum=0.9)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1729341591816,"user":{"displayName":"藤枝元輝","userId":"06257803041764381546"},"user_tz":-540},"id":"2zek9Nhrhq8D"},"outputs":[],"source":["import time\n","import copy\n","import torch.nn.utils.rnn as rnn_utils\n","def train_model(model, criterion, optimizer, scheduler, num_epochs):\n","    since = time.time()\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","    model.to(device)\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        # 各エポックには訓練フェーズと検証フェーズがあります\n","        for phase in ['Train', 'Test']:\n","            if phase == 'Train':\n","                model.train()  # モデルを訓練モードに設定します\n","            else:\n","                model.eval()   # モードを評価するモデルを設定します\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # データをイレテートします\n","            for frames,labels in img_dataloaders[phase]:\n","                frames = frames.to(device)\n","                labels = torch.tensor(labels).to(device)\n","                # パラメータの勾配をゼロにします\n","                optimizer.zero_grad()\n","\n","                # 順伝播\n","                # 訓練の時だけ、履歴を保持します\n","                with torch.set_grad_enabled(phase == 'Train'):\n","                    outputs = model(frames)\n","                    _, preds = torch.max(outputs[0], 1)\n","                    loss = criterion(outputs[0],labels)\n","                    # 訓練の時だけ逆伝播＋オプティマイズを行います\n","                    if phase == 'Train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # 損失を計算します\n","                running_loss += loss.item() * frames.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","            if phase == 'Train':\n","                scheduler.step()\n","\n","            epoch_loss = running_loss / dataset_sizes[phase]\n","            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n","                phase, epoch_loss, epoch_acc))\n","\n","            # モデルをディープ・コピーします\n","            if phase == 'Test' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","\n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(\n","        time_elapsed // 60, time_elapsed % 60))\n","    print('Best test Acc: {:4f}'.format(best_acc))\n","\n","    # ベストモデルの重みをロードします\n","    model.load_state_dict(best_model_wts)\n","    return model\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5WjAJIDETCvG"},"outputs":[],"source":["torch.save(model_ft.state_dict(), './gdrive/My Drive/CNN_LSTM_Model_weights_2024-10-17.pth')\n","# torch.save(model_ft.state_dict(), '$HOME/Desktop/CNN_LSTM_Model_weights_2024-10-17.pth')\n","import torch.onnx as onnx\n","input_image = torch.zeros((1,3,224,224)).to(device)\n","onnx.export(model_ft, input_image, './gdrive/My Drive/CNN_LSTM_Model_2024-10-17.onnx')\n","# onnx.export(model_ft, input_image, '$HOME/CNN_LSTM_Model_2024-10-17.onnx')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YYxlI5NoXdKb"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNwKq+qwkAcUhf5iGgalUOr","gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
